{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVect = kelimelerin cümle içindeki sıklıklarını hesaplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(server_name, database_name):\n",
    "    # Create a connection string\n",
    "    conn_string = (\n",
    "        f\"DRIVER={{SQL Server}};\"\n",
    "        f\"SERVER={server_name};\"\n",
    "        f\"DATABASE={database_name};\"\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the database\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "\n",
    "    # Create a cursor to execute queries\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve the data from the specified column\n",
    "    query = \"SELECT [strContent],[strNewsTitle]  FROM [ESSL].[dbo].[20220217_LocalNews_Found_Last_1_Month] WHERE [strContent] LIKE '%Yücel Gedik%' AND [strNewsTitle] LIKE '%Gedik%'\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Store the results in a list\n",
    "    results = cursor.fetchall()\n",
    "    stopwords = ['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n",
    "\n",
    "\n",
    "    # Create a list of tuples, where each tuple contains the strNewsTitle and strContent for a row\n",
    "    items = [(result[0], result[1]) for result in results if result[0] is not None and result[1] is not None]\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strNewsTitle\n",
    "    vectorizer_title = CountVectorizer(stop_words=stopwords)\n",
    "    \n",
    "\n",
    "    # Transform strNewsTitle into a matrix of token counts\n",
    "    title_matrix = vectorizer_title.fit_transform([item[1] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strNewsTitle\n",
    "    similarity_title = cosine_similarity(title_matrix)\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strContent\n",
    "    vectorizer_content = TfidfVectorizer(stop_words=stopwords)\n",
    "    vectorizer_content = TfidfVectorizer()\n",
    "\n",
    "    content_matrix = vectorizer_content.fit_transform([item[0] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strContent\n",
    "    similarity_content = cosine_similarity(content_matrix)\n",
    "\n",
    "    doc_term_matrix = title_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                    columns= vectorizer_title.get_feature_names()) \n",
    "\n",
    "    print(df.head(9))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bölge  dakika  doğrusöz  emanet  gazetesi  gedik  gedikali  gelecek  \\\n",
      "0      1       1         0       0         1      1         0        0   \n",
      "1      0       0         0       0         0      1         0        0   \n",
      "2      0       0         0       0         0      1         0        0   \n",
      "3      0       0         0       0         0      1         0        0   \n",
      "4      0       0         0       0         0      1         0        0   \n",
      "5      0       0         1       0         1      1         0        0   \n",
      "6      0       0         1       0         1      1         0        0   \n",
      "7      0       0         1       0         1      1         0        0   \n",
      "8      0       0         0       0         0      1         0        0   \n",
      "\n",
      "   gündemi  güven  ...  nda  odası  partisi  sebzeciler  sebzecilerden  son  \\\n",
      "0        1      1  ...    0      0        0           0              0    1   \n",
      "1        0      1  ...    1      1        0           1              0    0   \n",
      "2        0      1  ...    1      1        0           1              0    0   \n",
      "3        0      1  ...    1      1        0           1              0    0   \n",
      "4        0      1  ...    1      1        0           1              0    0   \n",
      "5        0      0  ...    0      0        0           0              1    0   \n",
      "6        0      0  ...    0      0        0           0              1    0   \n",
      "7        0      0  ...    0      0        0           0              1    0   \n",
      "8        0      1  ...    1      1        0           1              0    0   \n",
      "\n",
      "   tazeledi  ye  yücel  şehir  \n",
      "0         1   0      1      1  \n",
      "1         1   0      0      0  \n",
      "2         1   0      0      0  \n",
      "3         1   0      0      0  \n",
      "4         1   0      0      0  \n",
      "5         0   0      0      0  \n",
      "6         0   0      0      0  \n",
      "7         0   0      0      0  \n",
      "8         1   0      0      0  \n",
      "\n",
      "[9 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "calculate_similarity('DESKTOP-JT60920','ESSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(server_name, database_name):\n",
    "    # Create a connection string\n",
    "    conn_string = (\n",
    "        f\"DRIVER={{SQL Server}};\"\n",
    "        f\"SERVER={server_name};\"\n",
    "        f\"DATABASE={database_name};\"\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the database\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "\n",
    "    # Create a cursor to execute queries\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve the data from the specified column\n",
    "    query = \"SELECT [strContent],[strNewsTitle]  FROM [ESSL].[dbo].[20220217_LocalNews_Found_Last_1_Month] WHERE [strContent] LIKE '%Yücel Gedik%' AND [strNewsTitle] LIKE '%Gedik%'\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Store the results in a list\n",
    "    results = cursor.fetchall()\n",
    "    stopwords = ['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n",
    "\n",
    "\n",
    "    # Create a list of tuples, where each tuple contains the strNewsTitle and strContent for a row\n",
    "    items = [(result[0], result[1]) for result in results if result[0] is not None and result[1] is not None]\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strNewsTitle\n",
    "    vectorizer_title = CountVectorizer(stop_words=stopwords)\n",
    "    \n",
    "\n",
    "    # Transform strNewsTitle into a matrix of token counts\n",
    "    title_matrix = vectorizer_title.fit_transform([item[1] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strNewsTitle\n",
    "    similarity_title = cosine_similarity(title_matrix)\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strContent\n",
    "    vectorizer_content = TfidfVectorizer(stop_words=stopwords)\n",
    "    vectorizer_content = TfidfVectorizer()\n",
    "\n",
    "    content_matrix = vectorizer_content.fit_transform([item[0] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strContent\n",
    "    similarity_content = cosine_similarity(content_matrix)\n",
    "\n",
    "    \n",
    "    dj=pd.DataFrame(cosine_similarity( title_matrix,dense_output=True))\n",
    "    print(dj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  1.000000  1.000000  1.000000  1.000000  0.182574  0.182574  0.182574   \n",
      "1  1.000000  1.000000  1.000000  1.000000  0.182574  0.182574  0.182574   \n",
      "2  1.000000  1.000000  1.000000  1.000000  0.182574  0.182574  0.182574   \n",
      "3  1.000000  1.000000  1.000000  1.000000  0.182574  0.182574  0.182574   \n",
      "4  0.182574  0.182574  0.182574  0.182574  1.000000  1.000000  1.000000   \n",
      "\n",
      "         7         8         9   ...        12        13        14        15  \\\n",
      "0  1.000000  1.000000  1.000000  ...  0.182574  0.280976  0.280976  0.280976   \n",
      "1  1.000000  1.000000  1.000000  ...  0.182574  0.280976  0.280976  0.280976   \n",
      "2  1.000000  1.000000  1.000000  ...  0.182574  0.280976  0.280976  0.280976   \n",
      "3  1.000000  1.000000  1.000000  ...  0.182574  0.280976  0.280976  0.280976   \n",
      "4  0.182574  0.182574  0.182574  ...  1.000000  0.205196  0.205196  0.205196   \n",
      "\n",
      "         16        17        18        19   20        21  \n",
      "0  0.182574  0.280976  0.280976  0.280976  0.0  0.280976  \n",
      "1  0.182574  0.280976  0.280976  0.280976  0.0  0.280976  \n",
      "2  0.182574  0.280976  0.280976  0.280976  0.0  0.280976  \n",
      "3  0.182574  0.280976  0.280976  0.280976  0.0  0.280976  \n",
      "4  1.000000  0.205196  0.205196  0.205196  0.0  0.205196  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "calculate_similarity('DESKTOP-JT60920','ESSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(server_name, database_name):\n",
    "    # Create a connection string\n",
    "    conn_string = (\n",
    "        f\"DRIVER={{SQL Server}};\"\n",
    "        f\"SERVER={server_name};\"\n",
    "        f\"DATABASE={database_name};\"\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the database\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "\n",
    "    # Create a cursor to execute queries\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve the data from the specified column\n",
    "    query = \"SELECT [strContent],[strNewsTitle]  FROM [ESSL].[dbo].[20220217_LocalNews_Found_Last_1_Month] WHERE [strContent] LIKE '%Yücel Gedik%' AND [strNewsTitle] LIKE '%Gedik%'\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Store the results in a list\n",
    "    results = cursor.fetchall()\n",
    "    stopwords = ['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n",
    "\n",
    "\n",
    "    # Create a list of tuples, where each tuple contains the strNewsTitle and strContent for a row\n",
    "    items = [(result[0], result[1]) for result in results if result[0] is not None and result[1] is not None]\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strNewsTitle\n",
    "    vectorizer_title = CountVectorizer(stop_words=stopwords)\n",
    "    \n",
    "\n",
    "    # Transform strNewsTitle into a matrix of token counts\n",
    "    title_matrix = vectorizer_title.fit_transform([item[1] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strNewsTitle\n",
    "    similarity_title = cosine_similarity(title_matrix)\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strContent\n",
    "    vectorizer_content = TfidfVectorizer(stop_words=stopwords)\n",
    "    vectorizer_content = TfidfVectorizer()\n",
    "\n",
    "    content_matrix = vectorizer_content.fit_transform([item[0] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strContent\n",
    "    similarity_content = cosine_similarity(content_matrix)\n",
    "    \n",
    "    dj=pd.DataFrame(cosine_similarity( title_matrix,dense_output=True))\n",
    "    \n",
    "    t=[]\n",
    "\n",
    "    # Part 01:\n",
    "    for j,k in enumerate(dj.values):\n",
    "        for n in range(len(k)):\n",
    "            t.append([j,n,k[n]])\n",
    "\n",
    "    # Part 02:\n",
    "    liste=[]\n",
    "    for i in range(len(t)):\n",
    "        if t[i][0]==t[i][1]:\n",
    "            liste.append([t[i][0],t[i][1],0])\n",
    "        else:\n",
    "            liste.append(t[i])\n",
    "   # print(liste[:5])\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1.0000000000000002], [0, 1, 1.0000000000000002], [0, 2, 1.0000000000000002], [0, 3, 1.0000000000000002], [0, 4, 0.18257418583505539], [0, 5, 0.18257418583505539], [0, 6, 0.18257418583505539], [0, 7, 1.0000000000000002], [0, 8, 1.0000000000000002], [0, 9, 1.0000000000000002], [0, 10, 0.18257418583505539], [0, 11, 0.18257418583505539], [0, 12, 0.18257418583505539], [0, 13, 0.0], [0, 14, 0.18257418583505539], [0, 15, 0.2809757434745082], [0, 16, 0.2809757434745082], [0, 17, 0.2809757434745082], [0, 18, 0.2809757434745082], [0, 19, 0.2809757434745082], [0, 20, 0.2809757434745082], [0, 21, 0.2809757434745082], [1, 0, 1.0000000000000002], [1, 1, 1.0000000000000002], [1, 2, 1.0000000000000002], [1, 3, 1.0000000000000002], [1, 4, 0.18257418583505539], [1, 5, 0.18257418583505539], [1, 6, 0.18257418583505539], [1, 7, 1.0000000000000002], [1, 8, 1.0000000000000002], [1, 9, 1.0000000000000002], [1, 10, 0.18257418583505539], [1, 11, 0.18257418583505539], [1, 12, 0.18257418583505539], [1, 13, 0.0], [1, 14, 0.18257418583505539], [1, 15, 0.2809757434745082], [1, 16, 0.2809757434745082], [1, 17, 0.2809757434745082], [1, 18, 0.2809757434745082], [1, 19, 0.2809757434745082], [1, 20, 0.2809757434745082], [1, 21, 0.2809757434745082], [2, 0, 1.0000000000000002], [2, 1, 1.0000000000000002], [2, 2, 1.0000000000000002], [2, 3, 1.0000000000000002], [2, 4, 0.18257418583505539], [2, 5, 0.18257418583505539], [2, 6, 0.18257418583505539], [2, 7, 1.0000000000000002], [2, 8, 1.0000000000000002], [2, 9, 1.0000000000000002], [2, 10, 0.18257418583505539], [2, 11, 0.18257418583505539], [2, 12, 0.18257418583505539], [2, 13, 0.0], [2, 14, 0.18257418583505539], [2, 15, 0.2809757434745082], [2, 16, 0.2809757434745082], [2, 17, 0.2809757434745082], [2, 18, 0.2809757434745082], [2, 19, 0.2809757434745082], [2, 20, 0.2809757434745082], [2, 21, 0.2809757434745082], [3, 0, 1.0000000000000002], [3, 1, 1.0000000000000002], [3, 2, 1.0000000000000002], [3, 3, 1.0000000000000002], [3, 4, 0.18257418583505539], [3, 5, 0.18257418583505539], [3, 6, 0.18257418583505539], [3, 7, 1.0000000000000002], [3, 8, 1.0000000000000002], [3, 9, 1.0000000000000002], [3, 10, 0.18257418583505539], [3, 11, 0.18257418583505539], [3, 12, 0.18257418583505539], [3, 13, 0.0], [3, 14, 0.18257418583505539], [3, 15, 0.2809757434745082], [3, 16, 0.2809757434745082], [3, 17, 0.2809757434745082], [3, 18, 0.2809757434745082], [3, 19, 0.2809757434745082], [3, 20, 0.2809757434745082], [3, 21, 0.2809757434745082], [4, 0, 0.18257418583505539], [4, 1, 0.18257418583505539], [4, 2, 0.18257418583505539], [4, 3, 0.18257418583505539], [4, 4, 0.9999999999999999], [4, 5, 0.9999999999999999], [4, 6, 0.9999999999999999], [4, 7, 0.18257418583505539], [4, 8, 0.18257418583505539], [4, 9, 0.18257418583505539], [4, 10, 0.9999999999999999], [4, 11, 0.9999999999999999], [4, 12, 0.9999999999999999], [4, 13, 0.0], [4, 14, 0.9999999999999999], [4, 15, 0.2051956704170308], [4, 16, 0.2051956704170308], [4, 17, 0.2051956704170308], [4, 18, 0.2051956704170308], [4, 19, 0.2051956704170308], [4, 20, 0.2051956704170308], [4, 21, 0.2051956704170308], [5, 0, 0.18257418583505539], [5, 1, 0.18257418583505539], [5, 2, 0.18257418583505539], [5, 3, 0.18257418583505539], [5, 4, 0.9999999999999999], [5, 5, 0.9999999999999999], [5, 6, 0.9999999999999999], [5, 7, 0.18257418583505539], [5, 8, 0.18257418583505539], [5, 9, 0.18257418583505539], [5, 10, 0.9999999999999999], [5, 11, 0.9999999999999999], [5, 12, 0.9999999999999999], [5, 13, 0.0], [5, 14, 0.9999999999999999], [5, 15, 0.2051956704170308], [5, 16, 0.2051956704170308], [5, 17, 0.2051956704170308], [5, 18, 0.2051956704170308], [5, 19, 0.2051956704170308], [5, 20, 0.2051956704170308], [5, 21, 0.2051956704170308], [6, 0, 0.18257418583505539], [6, 1, 0.18257418583505539], [6, 2, 0.18257418583505539], [6, 3, 0.18257418583505539], [6, 4, 0.9999999999999999], [6, 5, 0.9999999999999999], [6, 6, 0.9999999999999999], [6, 7, 0.18257418583505539], [6, 8, 0.18257418583505539], [6, 9, 0.18257418583505539], [6, 10, 0.9999999999999999], [6, 11, 0.9999999999999999], [6, 12, 0.9999999999999999], [6, 13, 0.0], [6, 14, 0.9999999999999999], [6, 15, 0.2051956704170308], [6, 16, 0.2051956704170308], [6, 17, 0.2051956704170308], [6, 18, 0.2051956704170308], [6, 19, 0.2051956704170308], [6, 20, 0.2051956704170308], [6, 21, 0.2051956704170308], [7, 0, 1.0000000000000002], [7, 1, 1.0000000000000002], [7, 2, 1.0000000000000002], [7, 3, 1.0000000000000002], [7, 4, 0.18257418583505539], [7, 5, 0.18257418583505539], [7, 6, 0.18257418583505539], [7, 7, 1.0000000000000002], [7, 8, 1.0000000000000002], [7, 9, 1.0000000000000002], [7, 10, 0.18257418583505539], [7, 11, 0.18257418583505539], [7, 12, 0.18257418583505539], [7, 13, 0.0], [7, 14, 0.18257418583505539], [7, 15, 0.2809757434745082], [7, 16, 0.2809757434745082], [7, 17, 0.2809757434745082], [7, 18, 0.2809757434745082], [7, 19, 0.2809757434745082], [7, 20, 0.2809757434745082], [7, 21, 0.2809757434745082], [8, 0, 1.0000000000000002], [8, 1, 1.0000000000000002], [8, 2, 1.0000000000000002], [8, 3, 1.0000000000000002], [8, 4, 0.18257418583505539], [8, 5, 0.18257418583505539], [8, 6, 0.18257418583505539], [8, 7, 1.0000000000000002], [8, 8, 1.0000000000000002], [8, 9, 1.0000000000000002], [8, 10, 0.18257418583505539], [8, 11, 0.18257418583505539], [8, 12, 0.18257418583505539], [8, 13, 0.0], [8, 14, 0.18257418583505539], [8, 15, 0.2809757434745082], [8, 16, 0.2809757434745082], [8, 17, 0.2809757434745082], [8, 18, 0.2809757434745082], [8, 19, 0.2809757434745082], [8, 20, 0.2809757434745082], [8, 21, 0.2809757434745082], [9, 0, 1.0000000000000002], [9, 1, 1.0000000000000002], [9, 2, 1.0000000000000002], [9, 3, 1.0000000000000002], [9, 4, 0.18257418583505539], [9, 5, 0.18257418583505539], [9, 6, 0.18257418583505539], [9, 7, 1.0000000000000002], [9, 8, 1.0000000000000002], [9, 9, 1.0000000000000002], [9, 10, 0.18257418583505539], [9, 11, 0.18257418583505539], [9, 12, 0.18257418583505539], [9, 13, 0.0], [9, 14, 0.18257418583505539], [9, 15, 0.2809757434745082], [9, 16, 0.2809757434745082], [9, 17, 0.2809757434745082], [9, 18, 0.2809757434745082], [9, 19, 0.2809757434745082], [9, 20, 0.2809757434745082], [9, 21, 0.2809757434745082], [10, 0, 0.18257418583505539], [10, 1, 0.18257418583505539], [10, 2, 0.18257418583505539], [10, 3, 0.18257418583505539], [10, 4, 0.9999999999999999], [10, 5, 0.9999999999999999], [10, 6, 0.9999999999999999], [10, 7, 0.18257418583505539], [10, 8, 0.18257418583505539], [10, 9, 0.18257418583505539], [10, 10, 0.9999999999999999], [10, 11, 0.9999999999999999], [10, 12, 0.9999999999999999], [10, 13, 0.0], [10, 14, 0.9999999999999999], [10, 15, 0.2051956704170308], [10, 16, 0.2051956704170308], [10, 17, 0.2051956704170308], [10, 18, 0.2051956704170308], [10, 19, 0.2051956704170308], [10, 20, 0.2051956704170308], [10, 21, 0.2051956704170308], [11, 0, 0.18257418583505539], [11, 1, 0.18257418583505539], [11, 2, 0.18257418583505539], [11, 3, 0.18257418583505539], [11, 4, 0.9999999999999999], [11, 5, 0.9999999999999999], [11, 6, 0.9999999999999999], [11, 7, 0.18257418583505539], [11, 8, 0.18257418583505539], [11, 9, 0.18257418583505539], [11, 10, 0.9999999999999999], [11, 11, 0.9999999999999999], [11, 12, 0.9999999999999999], [11, 13, 0.0], [11, 14, 0.9999999999999999], [11, 15, 0.2051956704170308], [11, 16, 0.2051956704170308], [11, 17, 0.2051956704170308], [11, 18, 0.2051956704170308], [11, 19, 0.2051956704170308], [11, 20, 0.2051956704170308], [11, 21, 0.2051956704170308], [12, 0, 0.18257418583505539], [12, 1, 0.18257418583505539], [12, 2, 0.18257418583505539], [12, 3, 0.18257418583505539], [12, 4, 0.9999999999999999], [12, 5, 0.9999999999999999], [12, 6, 0.9999999999999999], [12, 7, 0.18257418583505539], [12, 8, 0.18257418583505539], [12, 9, 0.18257418583505539], [12, 10, 0.9999999999999999], [12, 11, 0.9999999999999999], [12, 12, 0.9999999999999999], [12, 13, 0.0], [12, 14, 0.9999999999999999], [12, 15, 0.2051956704170308], [12, 16, 0.2051956704170308], [12, 17, 0.2051956704170308], [12, 18, 0.2051956704170308], [12, 19, 0.2051956704170308], [12, 20, 0.2051956704170308], [12, 21, 0.2051956704170308], [13, 0, 0.0], [13, 1, 0.0], [13, 2, 0.0], [13, 3, 0.0], [13, 4, 0.0], [13, 5, 0.0], [13, 6, 0.0], [13, 7, 0.0], [13, 8, 0.0], [13, 9, 0.0], [13, 10, 0.0], [13, 11, 0.0], [13, 12, 0.0], [13, 13, 1.0000000000000002], [13, 14, 0.0], [13, 15, 0.0], [13, 16, 0.0], [13, 17, 0.0], [13, 18, 0.0], [13, 19, 0.0], [13, 20, 0.0], [13, 21, 0.0], [14, 0, 0.18257418583505539], [14, 1, 0.18257418583505539], [14, 2, 0.18257418583505539], [14, 3, 0.18257418583505539], [14, 4, 0.9999999999999999], [14, 5, 0.9999999999999999], [14, 6, 0.9999999999999999], [14, 7, 0.18257418583505539], [14, 8, 0.18257418583505539], [14, 9, 0.18257418583505539], [14, 10, 0.9999999999999999], [14, 11, 0.9999999999999999], [14, 12, 0.9999999999999999], [14, 13, 0.0], [14, 14, 0.9999999999999999], [14, 15, 0.2051956704170308], [14, 16, 0.2051956704170308], [14, 17, 0.2051956704170308], [14, 18, 0.2051956704170308], [14, 19, 0.2051956704170308], [14, 20, 0.2051956704170308], [14, 21, 0.2051956704170308], [15, 0, 0.2809757434745082], [15, 1, 0.2809757434745082], [15, 2, 0.2809757434745082], [15, 3, 0.2809757434745082], [15, 4, 0.2051956704170308], [15, 5, 0.2051956704170308], [15, 6, 0.2051956704170308], [15, 7, 0.2809757434745082], [15, 8, 0.2809757434745082], [15, 9, 0.2809757434745082], [15, 10, 0.2051956704170308], [15, 11, 0.2051956704170308], [15, 12, 0.2051956704170308], [15, 13, 0.0], [15, 14, 0.2051956704170308], [15, 15, 0.9999999999999996], [15, 16, 0.9999999999999996], [15, 17, 0.9999999999999996], [15, 18, 0.9999999999999996], [15, 19, 0.9999999999999996], [15, 20, 0.9999999999999996], [15, 21, 0.9999999999999996], [16, 0, 0.2809757434745082], [16, 1, 0.2809757434745082], [16, 2, 0.2809757434745082], [16, 3, 0.2809757434745082], [16, 4, 0.2051956704170308], [16, 5, 0.2051956704170308], [16, 6, 0.2051956704170308], [16, 7, 0.2809757434745082], [16, 8, 0.2809757434745082], [16, 9, 0.2809757434745082], [16, 10, 0.2051956704170308], [16, 11, 0.2051956704170308], [16, 12, 0.2051956704170308], [16, 13, 0.0], [16, 14, 0.2051956704170308], [16, 15, 0.9999999999999996], [16, 16, 0.9999999999999996], [16, 17, 0.9999999999999996], [16, 18, 0.9999999999999996], [16, 19, 0.9999999999999996], [16, 20, 0.9999999999999996], [16, 21, 0.9999999999999996], [17, 0, 0.2809757434745082], [17, 1, 0.2809757434745082], [17, 2, 0.2809757434745082], [17, 3, 0.2809757434745082], [17, 4, 0.2051956704170308], [17, 5, 0.2051956704170308], [17, 6, 0.2051956704170308], [17, 7, 0.2809757434745082], [17, 8, 0.2809757434745082], [17, 9, 0.2809757434745082], [17, 10, 0.2051956704170308], [17, 11, 0.2051956704170308], [17, 12, 0.2051956704170308], [17, 13, 0.0], [17, 14, 0.2051956704170308], [17, 15, 0.9999999999999996], [17, 16, 0.9999999999999996], [17, 17, 0.9999999999999996], [17, 18, 0.9999999999999996], [17, 19, 0.9999999999999996], [17, 20, 0.9999999999999996], [17, 21, 0.9999999999999996], [18, 0, 0.2809757434745082], [18, 1, 0.2809757434745082], [18, 2, 0.2809757434745082], [18, 3, 0.2809757434745082], [18, 4, 0.2051956704170308], [18, 5, 0.2051956704170308], [18, 6, 0.2051956704170308], [18, 7, 0.2809757434745082], [18, 8, 0.2809757434745082], [18, 9, 0.2809757434745082], [18, 10, 0.2051956704170308], [18, 11, 0.2051956704170308], [18, 12, 0.2051956704170308], [18, 13, 0.0], [18, 14, 0.2051956704170308], [18, 15, 0.9999999999999996], [18, 16, 0.9999999999999996], [18, 17, 0.9999999999999996], [18, 18, 0.9999999999999996], [18, 19, 0.9999999999999996], [18, 20, 0.9999999999999996], [18, 21, 0.9999999999999996], [19, 0, 0.2809757434745082], [19, 1, 0.2809757434745082], [19, 2, 0.2809757434745082], [19, 3, 0.2809757434745082], [19, 4, 0.2051956704170308], [19, 5, 0.2051956704170308], [19, 6, 0.2051956704170308], [19, 7, 0.2809757434745082], [19, 8, 0.2809757434745082], [19, 9, 0.2809757434745082], [19, 10, 0.2051956704170308], [19, 11, 0.2051956704170308], [19, 12, 0.2051956704170308], [19, 13, 0.0], [19, 14, 0.2051956704170308], [19, 15, 0.9999999999999996], [19, 16, 0.9999999999999996], [19, 17, 0.9999999999999996], [19, 18, 0.9999999999999996], [19, 19, 0.9999999999999996], [19, 20, 0.9999999999999996], [19, 21, 0.9999999999999996], [20, 0, 0.2809757434745082], [20, 1, 0.2809757434745082], [20, 2, 0.2809757434745082], [20, 3, 0.2809757434745082], [20, 4, 0.2051956704170308], [20, 5, 0.2051956704170308], [20, 6, 0.2051956704170308], [20, 7, 0.2809757434745082], [20, 8, 0.2809757434745082], [20, 9, 0.2809757434745082], [20, 10, 0.2051956704170308], [20, 11, 0.2051956704170308], [20, 12, 0.2051956704170308], [20, 13, 0.0], [20, 14, 0.2051956704170308], [20, 15, 0.9999999999999996], [20, 16, 0.9999999999999996], [20, 17, 0.9999999999999996], [20, 18, 0.9999999999999996], [20, 19, 0.9999999999999996], [20, 20, 0.9999999999999996], [20, 21, 0.9999999999999996], [21, 0, 0.2809757434745082], [21, 1, 0.2809757434745082], [21, 2, 0.2809757434745082], [21, 3, 0.2809757434745082], [21, 4, 0.2051956704170308], [21, 5, 0.2051956704170308], [21, 6, 0.2051956704170308], [21, 7, 0.2809757434745082], [21, 8, 0.2809757434745082], [21, 9, 0.2809757434745082], [21, 10, 0.2051956704170308], [21, 11, 0.2051956704170308], [21, 12, 0.2051956704170308], [21, 13, 0.0], [21, 14, 0.2051956704170308], [21, 15, 0.9999999999999996], [21, 16, 0.9999999999999996], [21, 17, 0.9999999999999996], [21, 18, 0.9999999999999996], [21, 19, 0.9999999999999996], [21, 20, 0.9999999999999996], [21, 21, 0.9999999999999996]]\n"
     ]
    }
   ],
   "source": [
    "calculate_similarity('DESKTOP-JT60920','ESSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "u=defaultdict(list)\n",
    "def calculate_similarity(server_name, database_name):\n",
    "    # Create a connection string\n",
    "    conn_string = (\n",
    "        f\"DRIVER={{SQL Server}};\"\n",
    "        f\"SERVER={server_name};\"\n",
    "        f\"DATABASE={database_name};\"\n",
    "    )\n",
    "\n",
    "    # Establish a connection to the database\n",
    "    conn = pyodbc.connect(conn_string)\n",
    "\n",
    "    # Create a cursor to execute queries\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve the data from the specified column\n",
    "    query = \"SELECT [strContent],[strNewsTitle]  FROM [ESSL].[dbo].[20220217_LocalNews_Found_Last_1_Month] WHERE [strContent] LIKE '%Yücel Gedik%' AND [strNewsTitle] LIKE '%Gedik%'\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Store the results in a list\n",
    "    results = cursor.fetchall()\n",
    "    stopwords = ['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n",
    "\n",
    "\n",
    "    # Create a list of tuples, where each tuple contains the strNewsTitle and strContent for a row\n",
    "    items = [(result[0], result[1]) for result in results if result[0] is not None and result[1] is not None]\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strNewsTitle\n",
    "    vectorizer_title = CountVectorizer(stop_words=stopwords)\n",
    "    \n",
    "\n",
    "    # Transform strNewsTitle into a matrix of token counts\n",
    "    title_matrix = vectorizer_title.fit_transform([item[1] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strNewsTitle\n",
    "    similarity_title = cosine_similarity(title_matrix)\n",
    "\n",
    "    # Create a CountVectorizer to calculate the cosine similarity for strContent\n",
    "    vectorizer_content = TfidfVectorizer(stop_words=stopwords)\n",
    "    vectorizer_content = TfidfVectorizer()\n",
    "\n",
    "    content_matrix = vectorizer_content.fit_transform([item[0] for item in items])\n",
    "\n",
    "    # Calculate the cosine similarity between strContent\n",
    "    similarity_content = cosine_similarity(content_matrix)\n",
    "    title=[item[1] for item in items]\n",
    "    dj=pd.DataFrame(cosine_similarity( title_matrix,dense_output=True))\n",
    "\n",
    "    t=[]\n",
    "\n",
    "    # Part 01:\n",
    "    for j,k in enumerate(dj.values):\n",
    "        for n in range(len(k)):\n",
    "            t.append([j,n,k[n]])\n",
    "\n",
    "    # Part 02:\n",
    "    liste=[]\n",
    "    for i in range(len(t)):\n",
    "        if t[i][0]==t[i][1]:\n",
    "            liste.append([t[i][0],t[i][1],0])\n",
    "        else:\n",
    "            liste.append(t[i])\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(liste)):\n",
    "        u[liste[i][0]].append(liste[i][2])\n",
    "        \n",
    "    updated_df=pd.DataFrame(u)\n",
    "\n",
    "    # updated_df.max(axis=1)\n",
    "    # max(updated_df[0])\n",
    "    # np.argmax(updated_df[3])\n",
    "    # updated_df[3]\n",
    "\n",
    "    # Part 02:\n",
    "\n",
    "    position_maxVal=[]\n",
    "    for i in range(len(updated_df)):\n",
    "        position_maxVal.append(np.argmax(updated_df[i]))\n",
    "    \n",
    "    sent_comp=[]\n",
    "\n",
    "\n",
    "    for j in position_maxVal: # list of highest similarity index positions\n",
    "    # this creates in order our tweets w/ highest similiarity by row    \n",
    "                sent_comp.append(title[j])\n",
    "    sent_comp\n",
    "\n",
    "    # tweets based on highest similarity value per row as DF\n",
    "    similar_tweets_=pd.DataFrame(sent_comp,columns=['Similar title'])\n",
    "\n",
    "    # similiarity values rounded 4 decimal places finding max value per row\n",
    "    similarity_value_=pd.DataFrame(round(updated_df.max(axis=1),4),\n",
    "                                columns=['Similarity Value'])\n",
    "    \n",
    "    # tweets w/o html in them\n",
    "    p_twt=pd.DataFrame(title,columns=['Parsed title'])\n",
    "\n",
    "    # put everything together\n",
    "    cos_sim_df=pd.concat([p_twt,similar_tweets_,similarity_value_],axis=1)\n",
    "\n",
    "\n",
    "    print(cos_sim_df['Parsed title'][0])\n",
    "    print('-----------------')\n",
    "    print(cos_sim_df['Similar title'][0])\n",
    "    print('-----------------')\n",
    "    print('Similarity Value:',cos_sim_df['Similarity Value'][33])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "33",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\esman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\range.py:392\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n\u001b[0;32m    393\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 33 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m calculate_similarity(\u001b[39m'\u001b[39m\u001b[39mDESKTOP-JT60920\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mESSL\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [50], line 105\u001b[0m, in \u001b[0;36mcalculate_similarity\u001b[1;34m(server_name, database_name)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m# put everything together\u001b[39;00m\n\u001b[0;32m    102\u001b[0m cos_sim_df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([p_twt,similar_tweets_,similarity_value_],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m \u001b[39mprint\u001b[39m(cos_sim_df[\u001b[39m'\u001b[39;49m\u001b[39mParsed title\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m33\u001b[39;49m])\n\u001b[0;32m    106\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-----------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[39mprint\u001b[39m(cos_sim_df[\u001b[39m'\u001b[39m\u001b[39mSimilar title\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m33\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\esman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:982\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    981\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 982\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    985\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    987\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1092\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1091\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1092\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1093\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\esman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\range.py:394\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[0;32m    393\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 394\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    396\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 33"
     ]
    }
   ],
   "source": [
    "calculate_similarity('DESKTOP-JT60920','ESSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab7bf1190d7c5832eadcc927c395fd0496966f425c8ea3336b36198bbaedf8ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
